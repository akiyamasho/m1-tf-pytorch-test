{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"data/anime_face\"\n",
    "\n",
    "IMAGE_DIM = 64\n",
    "BATCH_SIZE = 128\n",
    "CODE_SIZE = 100\n",
    "RGB_CHANNEL_COUNT = 3\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "BETA = 0.5\n",
    "EPOCHS = 2000\n",
    "\n",
    "CHECKPOINTS_FOLDER = \"checkpoints\"\n",
    "\n",
    "\n",
    "GEN_FOLDER = \"gen\"\n",
    "DISC_FOLDER = \"disc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63565 files belonging to 1 classes.\n",
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 01:40:03.081531: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-21 01:40:03.081683: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"data/anime_face\",\n",
    "    label_mode=None,\n",
    "    image_size=(IMAGE_DIM, IMAGE_DIM),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "dataset = dataset.map(lambda x: (x / 127.5) - 1)\n",
    "dataset = dataset.shuffle(buffer_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Input(shape=(CODE_SIZE,)),\n",
    "        tf.keras.layers.Dense(units=4 * 4 * 256),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.Reshape(target_shape=(4, 4, 256)),\n",
    "        tf.keras.layers.Conv2DTranspose(\n",
    "            filters=128, kernel_size=4, strides=2, padding=\"same\"\n",
    "        ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.Conv2DTranspose(\n",
    "            filters=64, kernel_size=4, strides=2, padding=\"same\"\n",
    "        ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.Conv2DTranspose(\n",
    "            32, kernel_size=4, strides=2, padding=\"same\"\n",
    "        ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.Conv2DTranspose(\n",
    "            3, kernel_size=4, strides=2, padding=\"same\"\n",
    "        ),\n",
    "        tf.keras.layers.Activation(\"tanh\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (IMAGE_DIM, IMAGE_DIM, RGB_CHANNEL_COUNT)\n",
    "discriminator = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(\n",
    "            32,\n",
    "            kernel_size=3,\n",
    "            strides=2,\n",
    "            input_shape=image_shape,\n",
    "            padding=\"same\",\n",
    "        ),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=3, strides=2, padding=\"same\"),\n",
    "        tf.keras.layers.ZeroPadding2D(padding=((0, 1), (0, 1))),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.8),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\"),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.8),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Conv2D(256, kernel_size=3, strides=1, padding=\"same\"),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.8),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adagrad(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    initial_accumulator_value=0.01,\n",
    ")\n",
    "discriminator_optimizer = tf.keras.optimizers.Adagrad(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    initial_accumulator_value=0.01,\n",
    ")\n",
    "\n",
    "\"\"\" generator_optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE, beta_1=BETA\n",
    ")\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE, beta_1=BETA\n",
    ")\n",
    " \"\"\"\n",
    "\n",
    "def discriminator_loss(real, fake):\n",
    "    real_loss = loss(tf.ones_like(real), real)\n",
    "    fake_loss = loss(tf.zeros_like(fake), fake)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "\n",
    "def generator_loss(fake):\n",
    "    gen_loss = loss(tf.ones_like(fake), fake)\n",
    "    return gen_loss\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([256, 100])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gen_grad = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    disc_grad = disc_tape.gradient(\n",
    "        disc_loss, discriminator.trainable_variables\n",
    "    )\n",
    "\n",
    "    generator_optimizer.apply_gradients(\n",
    "        zip(gen_grad, generator.trainable_variables)\n",
    "    )\n",
    "    discriminator_optimizer.apply_gradients(\n",
    "        zip(disc_grad, discriminator.trainable_variables)\n",
    "    )\n",
    "\n",
    "    return gen_loss, disc_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    gen_loss = 0\n",
    "    disc_loss = 0\n",
    "\n",
    "    gen_plot = []\n",
    "    disc_plot = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for image_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(image_batch)\n",
    "\n",
    "        gen_plot.append(gen_loss)\n",
    "        disc_plot.append(disc_loss)\n",
    "\n",
    "        if epoch % 25 == 0:\n",
    "            OUTPUT_FOLDER = os.path.join(CHECKPOINTS_FOLDER, f\"adagrad_epoch{epoch}-of-{EPOCHS}_lr{LEARNING_RATE}_beta{BETA}\")\n",
    "            GEN_CHECKPOINT_FOLDER = os.path.join(OUTPUT_FOLDER, GEN_FOLDER)\n",
    "            DISC_CHECKPOINT_FOLDER = os.path.join(OUTPUT_FOLDER, DISC_FOLDER)\n",
    "\n",
    "            generator.save(GEN_CHECKPOINT_FOLDER)\n",
    "            discriminator.save(DISC_CHECKPOINT_FOLDER)\n",
    "\n",
    "            noise = np.random.rand(32,100)\n",
    "            pred = generator.predict(noise)\n",
    "            tf.keras.preprocessing.image.save_img(os.path.join(OUTPUT_FOLDER, \"sample.png\"), pred[0,:,:])\n",
    "            display(tf.keras.preprocessing.image.array_to_img(pred[0]))\n",
    "\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            x = [X for X in range(epoch+1)]\n",
    "            plt.plot(x, gen_plot)\n",
    "            plt.plot(x, disc_plot)\n",
    "            plt.title(\"epoch vs loss\")\n",
    "            plt.legend([\"gen_loss\", \"dis_loss\"])\n",
    "            plt.xlabel(\"epochs\")\n",
    "            plt.ylabel(\"loss\")\n",
    "            plt.show()\n",
    "\n",
    "        print(\n",
    "            f\"epoch: {epoch}/{epochs}; G_loss: {gen_loss:.6f}; D_loss: {disc_loss:.6f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 01:40:09.249276: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-03-21 01:40:10.393174: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "train(dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 00:32:01.489059: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "noise = np.random.rand(32,100)\n",
    "pred = generator.predict(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(pred[i])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7a0a9d7ba9d0048b290b174152979f594ac9035e5cf6b8f0b5c496811b14dbb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('env_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
